{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed20da83-14e4-49c7-a747-cff0b5714f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torchmetrics\n",
    "from torch import nn, optim\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab19577e-0c33-4e24-a5de-29185f0e5bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, norm=False, padding='valid'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.BrchNorm = nn.BatchNorm2d(out_channels)\n",
    "        self.active = nn.LeakyReLU(inplace=True)\n",
    "        self.norm = norm\n",
    "\n",
    "    def forward(self,X):\n",
    "        X = self.conv(X)\n",
    "        if self.norm is True:\n",
    "            X = self.BrchNorm(X)\n",
    "        \n",
    "        return self.active(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf7ba755-6c8c-4518-99e6-421df20dca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding=0, norm=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.deconv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.BrchNorm = nn.BatchNorm2d(out_channels)\n",
    "        self.active = nn.ReLU(inplace=True)\n",
    "        self.norm = norm\n",
    "        \n",
    "    def forward(self,X):\n",
    "        X = self.deconv(X)\n",
    "        if self.norm is True:\n",
    "            X = self.BrchNorm(X)\n",
    "        \n",
    "        return self.active(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1132718-daa8-450d-900a-724308c2c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=4, stride=2, norm=False, padding='valid', use_dropout=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.Conv = ConvBlock(in_channels, out_channels, kernel_size, stride, norm=norm, padding=padding)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.use_dropout = use_dropout\n",
    "        \n",
    "    def forward(self,X):\n",
    "        X = self.Conv(X)\n",
    "        if self.use_dropout is True:\n",
    "            X = self.dropout(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0483890c-6c89-46a3-8de3-c059436e6b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,kernel_size=4, stride=2, padding=33, norm=True, use_dropout=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.deconv = deConvBlock(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, norm=norm)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.use_dropout = use_dropout\n",
    "        \n",
    "    def forward(self, X, skip):\n",
    "        if skip is not None:\n",
    "            X = torch.cat([X, skip], axis=1)\n",
    "        X = self.deconv(X)\n",
    "        if self.use_dropout is True:\n",
    "            X = self.dropout(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4087c460-0620-4d80-8f2f-cf54bc2d26c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticS2Image(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        \"\"\" Encoder \"\"\"\n",
    "        \n",
    "        # Sentinel-2_Before\n",
    "        self.s2b_conv1  = EncoderBlock(4, 64,padding=33) # Layer_1: 64*64*64\n",
    "        self.s2b_conv2  = EncoderBlock(64, 128,padding=33) # Layer_2: 128*64*64\n",
    "        self.s2b_conv3  = EncoderBlock(128, 256, padding=33) # Layer_3: 256*64*64\n",
    "        self.s2b_conv4  = EncoderBlock(256, 512, padding=33) # Layer_4: 512*64*64\n",
    "        \n",
    "        self.s2b_conv5  = EncoderBlock(512, 512, padding=33, use_dropout=True) # Layer_4: 512*64*64\n",
    "        self.s2b_conv6  = EncoderBlock(512, 512, padding=33, use_dropout=True) # Layer_4: 512*64*64\n",
    "        \n",
    "        # Sentinel-2_After\n",
    "        self.s2a_conv1  = EncoderBlock(4, 64,padding=33) # Layer_1: 64*64*64\n",
    "        self.s2a_conv2  = EncoderBlock(64, 128,padding=33) # Layer_2: 128*64*64\n",
    "        self.s2a_conv3  = EncoderBlock(128, 256, padding=33) # Layer_3: 256*64*64\n",
    "        self.s2a_conv4  = EncoderBlock(256, 512, padding=33) # Layer_4: 512*64*64\n",
    "        \n",
    "        self.s2a_conv5  = EncoderBlock(512, 512, padding=33, use_dropout=True) # Layer_4: 512*64*64\n",
    "        self.s2a_conv6  = EncoderBlock(512, 512, padding=33, use_dropout=True) # Layer_4: 512*64*64\n",
    "        \n",
    "        # Sentinel-1\n",
    "        self.s1_conv1  = EncoderBlock(2, 64,padding=33) # Layer_1: 64*64*64\n",
    "        self.s1_conv2  = EncoderBlock(64, 128,padding=33) # Layer_2: 128*64*64\n",
    "        self.s1_conv3  = EncoderBlock(128, 256, padding=33) # Layer_3: 256*64*64\n",
    "        self.s1_conv4  = EncoderBlock(256, 512, padding=33) # Layer_4: 512*64*64\n",
    "        \n",
    "        self.s1_conv5  = EncoderBlock(512, 512, padding=33, use_dropout=True) # Layer_4: 512*64*64\n",
    "        self.s1_conv6  = EncoderBlock(512, 512, padding=33, use_dropout=True) # Layer_4: 512*64*64\n",
    "\n",
    "        \n",
    "        \n",
    "        \"\"\" Decoder \"\"\"\n",
    "        self.u6 = DecoderBlock(1536, 512,padding=33)\n",
    "        self.u7 = DecoderBlock(2048, 512,padding=33)\n",
    "        self.u8 = DecoderBlock(2048, 256,padding=33)\n",
    "        self.u9 = DecoderBlock(1024, 128,padding=33)\n",
    "        self.u10 = DecoderBlock(512, 64,padding=33)\n",
    "        self.u11 = DecoderBlock(256, 4,padding=33,use_dropout=False)\n",
    "\n",
    "        \n",
    "    def forward(self,S2b, S2a, S1):\n",
    "        S2b1 = self.s2b_conv1(S2b)\n",
    "        S2b2 = self.s2b_conv2(S2b1)\n",
    "        S2b3 = self.s2b_conv3(S2b2)\n",
    "        S2b4 = self.s2b_conv4(S2b3)\n",
    "        S2b5 = self.s2b_conv5(S2b4)\n",
    "        S2b6 = self.s2b_conv6(S2b5)\n",
    "        \n",
    "        S2a1 = self.s2a_conv1(S2a)\n",
    "        S2a2 = self.s2a_conv2(S2a1)\n",
    "        S2a3 = self.s2a_conv3(S2a2)\n",
    "        S2a4 = self.s2a_conv4(S2a3)\n",
    "        S2a5 = self.s2a_conv5(S2a4)\n",
    "        S2a6 = self.s2a_conv6(S2a5)\n",
    "        \n",
    "        S11 = self.s1_conv1(S1)\n",
    "        S12 = self.s1_conv2(S11)\n",
    "        S13 = self.s1_conv3(S12)\n",
    "        S14 = self.s1_conv4(S13)\n",
    "        S15 = self.s1_conv5(S14)\n",
    "        S16 = self.s1_conv6(S15)\n",
    "\n",
    "        concat6 = torch.concat([S2b6,S2a6,S16], axis=1)\n",
    "        U6 = self.u6(concat6,None)\n",
    "        \n",
    "        concat5 = torch.concat([S2b5,S2a5,S15], axis=1)\n",
    "        U7 = self.u7(U6,concat5)\n",
    "        \n",
    "        concat4 = torch.concat([S2b4,S2a4,S14], axis=1)\n",
    "        U8 = self.u8(U7,concat4)\n",
    "        \n",
    "        concat3 = torch.concat([S2b3,S2a3,S13], axis=1)\n",
    "        U9 = self.u9(U8,concat3)\n",
    "        \n",
    "        concat2 = torch.concat([S2b2,S2a2,S12], axis=1)\n",
    "        U10 = self.u10(U9,concat2)\n",
    "        \n",
    "        concat1 = torch.concat([S2b1,S2a1,S11], axis=1)\n",
    "        U11 = self.u11(U10,concat1)\n",
    "        \n",
    "        return U11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e7d6626-588c-49a1-9464-7840fb0e2638",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2b = torch.rand(1,4,64,64)\n",
    "s2a = torch.rand(1,4,64,64)\n",
    "s1 = torch.rand(1,2,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db962a33-c78b-4c93-8b69-785f586f7cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = SyntheticS2Image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d394de9-75ff-43c4-8293-81e3436befe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 64, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(s2b,s2a,s1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3a1d6c-6b9a-4385-ab5b-b35062662bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
